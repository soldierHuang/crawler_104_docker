# docker-compose.yml
# -----------------------------------------------------------------------------
# 專案完整服務定義
# 包含：核心服務、監控工具、Celery Worker、API 服務、以及一次性的任務觸發器
# -----------------------------------------------------------------------------
services:
  # --------------------------------------------------
  # 1. Core Dependencies (Database, Message Broker)
  # --------------------------------------------------
  mysql:
    image: mysql:8.0
    hostname: mysql
    command: --default-authentication-plugin=mysql_native_password
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql
    networks:
      - crawler-net
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u${MYSQL_USER}", "-p${MYSQL_PASSWORD}"]
      interval: 5s
      timeout: 10s
      retries: 10
    restart: always

  rabbitmq:
    image: 'rabbitmq:3.9-management-alpine'
    hostname: rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_DEFAULT_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_DEFAULT_PASS}
    ports:
      - '5672:5672'
      - '15672:15672'
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq/
    networks:
      - crawler-net
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: always

  # --------------------------------------------------
  # 2. Monitoring & Management
  # --------------------------------------------------
  phpmyadmin:
    image: phpmyadmin/phpmyadmin:5.2
    restart: always
    ports:
      # [關鍵修正] 將主機端口從 8000 改為 8080，以避免與 API 服務衝突
      - "8080:80" 
    environment:
      PMA_HOST: mysql
      PMA_PORT: 3306
    networks:
      - crawler-net
    depends_on:
      mysql:
        condition: service_healthy

  flower:
    image: mher/flower:2.0
    restart: always
    command: >
      celery --broker=amqp://${RABBITMQ_DEFAULT_USER}:${RABBITMQ_DEFAULT_PASS}@rabbitmq:5672/ flower
    ports:
      - "5555:5555"
    env_file:
      - ./.env
    networks:
      - crawler-net
    depends_on:
      rabbitmq:
        condition: service_healthy

  # --------------------------------------------------
  # 3. Application Logic (Long-running Services)
  # --------------------------------------------------
  worker-104:
    build: .
    hostname: worker-104
    command: celery -A crawler.worker worker -l info -Q worker_104
    volumes:
      - .:/home/app_user/app
    env_file:
      - ./.env
    networks:
      - crawler-net
    deploy:
      resources:
        limits:
          memory: 2G
    depends_on:
      mysql:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy

  api:
    build: .
    hostname: api
    command: uvicorn crawler.api.main:app --host 0.0.0.0 --port 8000 --reload
    ports:
      # API 服務使用主機的 8000 端口
      - "8000:8000"
    volumes:
      - .:/home/app_user/app
    env_file:
      - ./.env
    networks:
      - crawler-net
    depends_on:
      mysql:
        condition: service_healthy

  # --------------------------------------------------
  # 4. Task Producers (Defined for `docker compose run`)
  # --------------------------------------------------
  producer-category:
    build: .
    command: python -m crawler.project_104.producer_category
    env_file:
      - ./.env
    networks:
      - crawler-net
    depends_on:
      rabbitmq:
        condition: service_healthy

  producer-urls:
    build: .
    command: python -m crawler.project_104.producer_urls
    env_file:
      - ./.env
    networks:
      - crawler-net
    depends_on:
      rabbitmq:
        condition: service_healthy

  producer-job-details:
    build: .
    command: python -m crawler.project_104.producer_job_details
    env_file:
      - ./.env
    networks:
      - crawler-net
    depends_on:
      rabbitmq:
        condition: service_healthy

# --------------------------------------------------
# Network & Volume Definitions
# --------------------------------------------------
networks:
  crawler-net:
    driver: bridge

volumes:
  mysql_data:
  rabbitmq_data: